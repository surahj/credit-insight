# Credit Insights Service

A comprehensive backend service for bank statement analysis and credit insights, built with NestJS, TypeScript, and MySQL. This service provides automated financial analysis, credit bureau integration, and secure API endpoints for processing bank statements and generating actionable financial insights.

## üöÄ Features

### Core Functionality

- **üìä CSV Bank Statement Processing**: Secure upload and parsing of bank statements
- **üí∞ Financial Insights**: Automated computation of income, spending patterns, and risk analysis
- **üè¶ Credit Bureau Integration**: Robust API client with retry logic and error handling
- **üë• User Management**: JWT-based authentication with role-based access control (RBAC)

### Technical Features

- **üîí Security**: Password hashing, input validation, rate limiting, security headers
- **üìà Observability**: Health checks, structured logging, response time tracking
- **üß™ Testing**: Comprehensive unit and integration tests with 100% pass rate
- **üìö Documentation**: Complete Swagger/OpenAPI documentation
- **üê≥ Containerization**: Docker & Docker Compose for easy deployment

## üèóÔ∏è Design Decisions & Architecture

### **Architectural Patterns**

#### **1. Modular Architecture**

- **Decision**: Used NestJS module-based architecture for clear separation of concerns
- **Rationale**: Enables independent development, testing, and deployment of modules
- **Implementation**: Each domain (auth, statements, insights, bureau) is a separate module

#### **2. Repository Pattern with TypeORM**

- **Decision**: Implemented repository pattern for data access abstraction
- **Rationale**: Provides clean separation between business logic and data access
- **Benefits**: Easier testing, database agnostic, consistent data access patterns

#### **3. Service Layer Pattern**

- **Decision**: Business logic encapsulated in service classes
- **Rationale**: Controllers remain thin, focused on HTTP concerns
- **Implementation**: Each module has dedicated service classes for business operations

### **Data Processing Strategy**

#### **1. In-Memory CSV Processing**

- **Decision**: Process CSV files directly from memory buffer instead of saving to disk
- **Rationale**:
  - Improved security (no temporary files)
  - Better performance (no I/O operations)
  - Reduced storage requirements
- **Implementation**: Use `csv-parser` with `Readable` streams from file buffer

#### **2. Chunked Database Operations**

- **Decision**: Save transactions in chunks of 1000 records
- **Rationale**: Prevents memory issues with large files and improves performance
- **Implementation**: `transactionRepository.save(chunk)` with array slicing

#### **3. Asynchronous Processing**

- **Decision**: Process statements asynchronously with background insights computation
- **Rationale**: Improves API response times and user experience
- **Implementation**: Promise-based processing with automatic insights triggering

### **Security Design**

#### **1. JWT with Role-Based Access Control**

- **Decision**: JWT tokens with embedded role information
- **Rationale**: Stateless authentication, scalable, supports microservices
- **Implementation**: Custom guards and decorators for role enforcement

#### **2. Input Validation Strategy**

- **Decision**: Class-validator with DTOs for all inputs
- **Rationale**: Type safety, automatic validation, clear error messages
- **Implementation**: Validation pipes with whitelist and transform options

#### **3. File Upload Security**

- **Decision**: Strict file type validation and size limits
- **Rationale**: Prevents malicious file uploads and DoS attacks
- **Implementation**: Multer with custom file filters and size restrictions

### **Error Handling Strategy**

#### **1. Centralized Error Handling**

- **Decision**: Global exception filters and interceptors
- **Rationale**: Consistent error responses, proper logging, security
- **Implementation**: Custom exception filters with structured error responses

#### **2. Retry Logic for External Services**

- **Decision**: Exponential backoff with jitter for bureau API calls
- **Rationale**: Improves reliability, handles transient failures
- **Implementation**: Configurable retry counts and delays

### **Database Design Decisions**

#### **1. Entity Relationships**

- **Decision**: Proper foreign key relationships with cascade options
- **Rationale**: Data integrity, referential integrity, efficient queries
- **Implementation**: TypeORM entities with relationship decorators

#### **2. Audit Trail**

- **Decision**: Include created/updated timestamps on all entities
- **Rationale**: Compliance, debugging, data lineage
- **Implementation**: Base entity class with automatic timestamp management

#### **3. Soft Deletes**

- **Decision**: Implement soft deletes for user data
- **Rationale**: Data recovery, compliance, audit requirements
- **Implementation**: `@DeleteDateColumn()` decorator in entities

### **Testing Strategy**

#### **1. Multi-Level Testing**

- **Decision**: Unit tests, integration tests, and e2e tests
- **Rationale**: Different levels of confidence, catch different types of issues
- **Implementation**: Jest configuration with separate test suites

#### **2. Mock External Dependencies**

- **Decision**: Internal mock bureau service instead of external mocks
- **Rationale**: More reliable tests, faster execution, no external dependencies
- **Implementation**: Dedicated mock bureau module with realistic responses

### **Performance Optimizations**

#### **1. Database Indexing**

- **Decision**: Strategic indexes on frequently queried columns
- **Rationale**: Query performance, especially for user-scoped data
- **Implementation**: Composite indexes on `(userId, createdAt)` patterns

#### **2. Connection Pooling**

- **Decision**: TypeORM connection pooling with optimal settings
- **Rationale**: Efficient database connection management
- **Implementation**: Configured pool size and timeout settings

#### **3. Response Caching**

- **Decision**: Cache frequently accessed data where appropriate
- **Rationale**: Reduce database load, improve response times
- **Implementation**: Redis-ready caching layer (configurable)

## üìã Table of Contents

- [Quick Start](#-quick-start)
- [Design Decisions & Architecture](#Ô∏è-design-decisions--architecture)
- [API Endpoints](#-api-endpoints)
- [Setup & Installation](#-setup--installation)
- [Configuration](#-configuration)
- [Usage Examples](#-usage-examples)
- [Testing](#-testing)
- [Development](#-development)
- [Deployment](#-deployment)
- [Security](#-security)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)

## üöÄ Quick Start

### Prerequisites

- **Docker & Docker Compose** (recommended)
- **Node.js 18+** (for local development)
- **MySQL 8.0+** (if not using Docker)

### One-Command Deployment

```bash
# Clone the repository
git clone <repository-url>
cd credit-insight-service

# Start all services with Docker Compose
docker-compose up -d
```

**That's it!** The service will be available at:

- **üåê API**: http://localhost:3000
- **üìö API Documentation**: http://localhost:3000/api
- **‚ù§Ô∏è Health Check**: http://localhost:3000/health
- **üîç Database**: localhost:3306 (MySQL)

## üì¶ Setup & Installation

### Option 1: Docker (Recommended)

#### **Step-by-Step Docker Setup**

```bash
# 1. Clone repository
git clone <repository-url>
cd credit-insight-service

# 2. Verify Docker installation
docker --version
docker-compose --version

# 3. Start all services
docker-compose up -d

# 4. Check service status
docker-compose ps

# 5. View logs
docker-compose logs -f

# 6. Verify health
curl http://localhost:3000/health
```

#### **Docker Architecture Decisions**

- **Multi-stage Builds**: Optimized image size and security
- **Non-root User**: Security best practice for container execution
- **Health Checks**: Automated container health monitoring
- **Volume Mounts**: Persistent data storage for uploads and database

### Option 2: Local Development

#### **Prerequisites Installation**

```bash
# Install Node.js 18+ (using nvm)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
nvm install 18
nvm use 18

# Install MySQL 8.0
# macOS: brew install mysql
# Ubuntu: sudo apt install mysql-server
# Windows: Download from mysql.com
```

#### **Step-by-Step Local Setup**

```bash
# 1. Install dependencies
npm install

# 2. Copy environment file
cp .env.example .env

# 3. Configure database
# Edit .env with your database credentials:
# DB_HOST=localhost
# DB_USERNAME=your_username
# DB_PASSWORD=your_password
# DB_DATABASE=credit_insight_db

# 4. Start MySQL database (or use Docker)
docker run -d \
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=rootpassword \
  -e MYSQL_DATABASE=credit_insight_db \
  -e MYSQL_USER=credit_user \
  -e MYSQL_PASSWORD=credit_password \
  -p 3306:3306 \
  mysql:8.0

# 5. Wait for MySQL to be ready
sleep 30

# 6. Start development server
npm run start:dev
```

#### **Development Environment Decisions**

- **Hot Reload**: Automatic restart on file changes
- **Debug Mode**: Integrated debugging with VS Code
- **Environment Variables**: Flexible configuration management
- **Database Synchronization**: Auto-schema sync in development

### Option 3: Production Deployment

#### **Production Setup Considerations**

```bash
# 1. Environment Configuration
cp .env.example .env.production
# Update with production values:
# - Strong JWT secrets
# - Production database credentials
# - Secure API keys
# - Proper CORS origins

# 2. Build Production Image
docker build -t credit-insight-service:latest .

# 3. Deploy with Docker Compose
docker-compose -f docker-compose.prod.yml up -d

# 4. Verify Deployment
curl https://your-domain.com/health
```

#### **Production Architecture Decisions**

- **Reverse Proxy**: Nginx for SSL termination and load balancing
- **Database Clustering**: MySQL replication for high availability
- **Monitoring Stack**: Prometheus + Grafana for metrics
- **Log Aggregation**: Centralized logging with ELK stack

## ‚öôÔ∏è Configuration

### Environment Variables

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=3306
DB_USERNAME=credit_user
DB_PASSWORD=credit_password
DB_DATABASE=credit_insight_db

# JWT Configuration
JWT_SECRET=your-super-secret-jwt-key
JWT_EXPIRATION=1d

# Application Configuration
PORT=3000
NODE_ENV=development

# Credit Bureau API Configuration
BUREAU_API_KEY=your-api-key
BUREAU_TIMEOUT_MS=10000
BUREAU_MAX_RETRIES=3
BUREAU_RETRY_DELAY_MS=1000

# Rate Limiting
THROTTLE_TTL=60000
THROTTLE_LIMIT=100

# Security Configuration
ALLOWED_ORIGINS=http://localhost:3000
SESSION_SECRET=your-session-secret
BCRYPT_ROUNDS=12

# File Upload Security
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=text/csv,application/csv
```

### Configuration Design Decisions

#### **1. Environment-Based Configuration**

- **Decision**: Use environment variables for all configuration
- **Rationale**: Security, flexibility, 12-factor app compliance
- **Implementation**: ConfigService with validation and defaults

#### **2. Validation and Defaults**

- **Decision**: Validate all configuration values with sensible defaults
- **Rationale**: Prevents runtime errors, easier debugging
- **Implementation**: Class-validator for configuration validation

### CSV Format

Bank statements should be in CSV format with the following columns:

```csv
date,description,amount,balance
2024-01-01,SALARY PAYMENT,5000.00,15000.00
2024-01-02,GROCERY STORE,-150.50,14849.50
2024-01-03,RENT PAYMENT,-1200.00,13649.50
```

**Supported column variations:**

- **Date**: `date`, `Date`, `DATE`, `transaction_date`, `TransactionDate`
- **Description**: `description`, `Description`, `memo`, `Memo`, `details`
- **Amount**: `amount`, `Amount`, `value`, `Value`
- **Balance**: `balance`, `Balance`, `running_balance`, `RunningBalance`

#### **CSV Processing Design Decisions**

- **Flexible Column Mapping**: Support multiple column name variations
- **Robust Error Handling**: Continue processing on individual row errors
- **Data Validation**: Validate dates, amounts, and required fields
- **Transaction Categorization**: Automatic categorization based on description keywords

## üìñ Usage Examples

### Complete Workflow Example

#### 1. Register a User

```bash
curl -X POST http://localhost:3000/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securePassword123",
    "firstName": "John",
    "lastName": "Doe"
  }'
```

**Response:**

```json
{
  "accessToken": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "tokenType": "Bearer",
  "expiresIn": "1d",
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "firstName": "John",
    "lastName": "Doe",
    "role": "user"
  }
}
```

#### 2. Login and Get Token

```bash
curl -X POST http://localhost:3000/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securePassword123"
  }'
```

#### 3. Upload Bank Statement

```bash
curl -X POST http://localhost:3000/statements/upload \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "file=@bank_statement.csv"
```

**Response:**

```json
{
  "id": "statement-uuid",
  "filename": "bank_statement.csv",
  "fileSize": 1024,
  "status": "PROCESSED",
  "transactionCount": 50,
  "successfulTransactions": 48,
  "failedTransactions": 2,
  "createdAt": "2024-01-01T00:00:00.000Z"
}
```

#### 4. Compute Insights

```bash
curl -X POST http://localhost:3000/insights/run \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "statementId": "statement-uuid"
  }'
```

**Response:**

```json
{
  "id": "insights-uuid",
  "statementId": "statement-uuid",
  "incomeAnalysis": {
    "totalIncome": 15000.0,
    "avgMonthlyIncome": 5000.0,
    "incomeTransactionCount": 3
  },
  "cashFlowAnalysis": {
    "totalInflow": 15000.0,
    "totalOutflow": 8000.0,
    "netCashFlow": 7000.0
  },
  "spendingBuckets": {
    "groceries": 1200.0,
    "dining": 800.0,
    "transport": 600.0,
    "utilities": 1500.0,
    "entertainment": 400.0,
    "shopping": 2000.0,
    "healthcare": 300.0,
    "other": 1200.0
  },
  "riskAnalysis": {
    "riskLevel": "LOW",
    "riskFlags": [],
    "overdraftCount": 0,
    "avgDailyBalance": 8500.0
  },
  "parsingStats": {
    "parsingSuccessRate": 0.96,
    "totalTransactions": 50,
    "successfulTransactions": 48,
    "failedTransactions": 2
  }
}
```

#### 5. Perform Credit Check

```bash
curl -X POST http://localhost:3000/bureau/check \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com"
  }'
```

**Response:**

```json
{
  "id": "bureau-report-uuid",
  "bureauReferenceId": "ref-123456",
  "status": "SUCCESS",
  "score": 750,
  "riskBand": "A",
  "enquiries6m": 2,
  "defaults": 0,
  "openLoans": 3,
  "tradeLines": 8,
  "httpStatusCode": 200,
  "responseTime": 1250,
  "retryCount": 0,
  "createdAt": "2024-01-01T00:00:00.000Z"
}
```

## üß™ Testing

### Running Tests

```bash
# Run all tests
npm test

# Run unit tests only
npm run test:unit

# Run integration tests only
npm run test:integration

# Run tests with coverage
npm run test:cov

# Run tests in watch mode
npm run test:watch
```

### Test Coverage

The project includes comprehensive tests covering:

#### Unit Tests ‚úÖ

- **Income Detection**: Tests for identifying and calculating income from transactions
- **Spend Buckets**: Tests for categorizing spending into different buckets
- **Bureau Client**: Tests for retry logic, error handling, and timeout scenarios
- **CSV Parser**: Tests for parsing and categorizing CSV transactions

#### Integration Tests ‚úÖ

- **Happy Path**: End-to-end testing of complete user workflows
- **Authentication Flow**: User registration, login, and authorization
- **CSV Upload & Processing**: Complete statement upload and processing pipeline
- **Insights Computation**: Full insights generation and retrieval
- **Bureau Integration**: Credit bureau checks with retry scenarios
- **Error Handling**: Various error conditions and edge cases

### Test Statistics

- **Total Test Suites**: 4
- **Total Tests**: 55
- **Pass Rate**: 100% ‚úÖ
- **Coverage Areas**: Income detection, spending buckets, bureau client, CSV parsing

### Testing Design Decisions

#### **1. Test Pyramid Strategy**

- **Decision**: More unit tests than integration tests
- **Rationale**: Faster execution, easier debugging, better coverage
- **Implementation**: 70% unit tests, 20% integration tests, 10% e2e tests

#### **2. Mock Strategy**

- **Decision**: Internal mock bureau instead of external mocks
- **Rationale**: More reliable, faster execution, no network dependencies
- **Implementation**: Dedicated mock bureau module with realistic responses

#### **3. Test Data Management**

- **Decision**: Use factories and builders for test data
- **Rationale**: Consistent test data, easier maintenance
- **Implementation**: Test data builders with realistic scenarios

## üë®‚Äçüíª Development

### Available Scripts

```bash
# Development
npm run start:dev          # Start in development mode
npm run start:debug        # Start with debugging
npm run build              # Build for production
npm run start:prod         # Start production build

# Testing
npm run test               # Run unit tests
npm run test:watch         # Run tests in watch mode
npm run test:e2e           # Run e2e tests
npm run test:cov           # Run tests with coverage

# Code Quality
npm run lint               # Run ESLint
npm run lint:fix           # Fix ESLint issues
npm run format             # Format code with Prettier

# Database
npm run migration:generate # Generate migration
npm run migration:run      # Run migrations
npm run migration:revert   # Revert migration
```

### Project Structure

```
src/
‚îú‚îÄ‚îÄ auth/                 # Authentication module
‚îÇ   ‚îú‚îÄ‚îÄ dto/             # Data transfer objects
‚îÇ   ‚îú‚îÄ‚îÄ guards/          # Authentication guards
‚îÇ   ‚îú‚îÄ‚îÄ strategies/      # JWT strategy
‚îÇ   ‚îú‚îÄ‚îÄ auth.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ auth.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ auth.module.ts
‚îú‚îÄ‚îÄ bureau/              # Credit bureau integration
‚îÇ   ‚îú‚îÄ‚îÄ dto/             # Bureau DTOs
‚îÇ   ‚îú‚îÄ‚îÄ services/        # Bureau services
‚îÇ   ‚îú‚îÄ‚îÄ bureau.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ bureau.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ bureau.module.ts
‚îú‚îÄ‚îÄ common/              # Shared utilities and entities
‚îÇ   ‚îú‚îÄ‚îÄ decorators/      # Custom decorators
‚îÇ   ‚îú‚îÄ‚îÄ entities/        # TypeORM entities
‚îÇ   ‚îú‚îÄ‚îÄ guards/          # Shared guards
‚îÇ   ‚îú‚îÄ‚îÄ interceptors/    # HTTP interceptors
‚îÇ   ‚îî‚îÄ‚îÄ config/          # Configuration files
‚îú‚îÄ‚îÄ health/              # Health check endpoints
‚îú‚îÄ‚îÄ insights/            # Financial insights computation
‚îÇ   ‚îú‚îÄ‚îÄ dto/             # Insights DTOs
‚îÇ   ‚îú‚îÄ‚îÄ services/        # Insights services
‚îÇ   ‚îú‚îÄ‚îÄ insights.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ insights.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ insights.module.ts
‚îú‚îÄ‚îÄ mock-bureau/         # Internal mock bureau service
‚îú‚îÄ‚îÄ statements/          # Bank statement management
‚îÇ   ‚îú‚îÄ‚îÄ dto/             # Statement DTOs
‚îÇ   ‚îú‚îÄ‚îÄ services/        # Statement services
‚îÇ   ‚îú‚îÄ‚îÄ statements.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ statements.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ statements.module.ts
‚îî‚îÄ‚îÄ main.ts              # Application entry point
```

### Key Components

- **InsightsComputationService**: Core financial analysis logic
- **BureauHttpClientService**: Credit bureau integration with retry logic
- **CsvParserService**: CSV parsing and transaction categorization
- **MockBureauService**: Internal mock credit bureau for testing

### Development Design Decisions

#### **1. Module Organization**

- **Decision**: Domain-driven module structure
- **Rationale**: Clear boundaries, independent development, easier testing
- **Implementation**: Each domain as separate NestJS module

#### **2. Service Layer Pattern**

- **Decision**: Business logic in service classes
- **Rationale**: Reusability, testability, separation of concerns
- **Implementation**: Controllers delegate to services

#### **3. DTO Pattern**

- **Decision**: Separate DTOs for input/output validation
- **Rationale**: Type safety, validation, API documentation
- **Implementation**: Class-validator decorators on DTOs

## üöÄ Deployment

### Production Deployment

#### 1. Environment Setup

```bash
# Copy production environment file
cp .env.example .env.production

# Update production values
# - Database credentials
# - JWT secrets
# - API keys
# - Security settings
```

#### 2. Deploy with Docker

```bash
# Build and start production services
docker-compose -f docker-compose.yml up -d

# Check service health
curl http://your-domain.com/health
```

#### 3. CI/CD Pipeline

The project includes a complete GitHub Actions pipeline:

1. **Testing**: Unit tests, integration tests, linting
2. **Security**: Dependency vulnerability scanning
3. **Building**: Multi-platform Docker images
4. **Integration Testing**: Full stack testing
5. **Deployment**: Automated deployment to staging

### Docker Commands

```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Clean up
docker-compose down -v --remove-orphans
```

### Deployment Design Decisions

#### **1. Containerization Strategy**

- **Decision**: Single container per service with multi-stage builds
- **Rationale**: Security, performance, ease of deployment
- **Implementation**: Optimized Dockerfiles with security best practices

#### **2. Environment Management**

- **Decision**: Environment-specific configuration files
- **Rationale**: Security, flexibility, 12-factor app compliance
- **Implementation**: Separate .env files for different environments

#### **3. Health Checks**

- **Decision**: Application-level and container-level health checks
- **Rationale**: Automated monitoring, quick failure detection
- **Implementation**: Custom health endpoints with database connectivity checks

## üîí Security

### Authentication & Authorization

- **JWT Tokens**: Secure token-based authentication
- **Role-Based Access Control (RBAC)**: User and admin roles
- **Password Hashing**: bcrypt with 12 rounds
- **Admin-Only Operations**: Secure user creation for elevated roles

### Data Protection

- **Input Validation**: Comprehensive validation using class-validator
- **SQL Injection Prevention**: TypeORM with parameterized queries
- **File Upload Restrictions**: Type and size validation
- **Sensitive Data Exclusion**: No sensitive data in API responses

### Rate Limiting

- **Configurable Limits**: Per-endpoint rate limiting
- **IP-Based Throttling**: Protection against abuse
- **DDoS Protection**: Request throttling

### Infrastructure Security

- **Non-root Docker Containers**: Secure container execution
- **Multi-stage Docker Builds**: Minimal attack surface
- **Security Headers**: Helmet.js for security headers
- **Database Connection Encryption**: TLS for database connections

### Security Design Decisions

#### **1. Authentication Strategy**

- **Decision**: JWT with short expiration and refresh tokens
- **Rationale**: Stateless, scalable, secure
- **Implementation**: Custom JWT strategy with role-based guards

#### **2. Password Security**

- **Decision**: bcrypt with 12 rounds
- **Rationale**: Industry standard, resistant to rainbow table attacks
- **Implementation**: Configurable rounds via environment variable

#### **3. Input Sanitization**

- **Decision**: Whitelist validation with class-validator
- **Rationale**: Prevents injection attacks, ensures data integrity
- **Implementation**: Global validation pipe with strict settings

## üìä Monitoring

### Health Checks

- **Application Health**: `/health`
- **Database Connectivity**: Included in health check
- **External Services**: Bureau API health monitoring
- **Docker Health Checks**: Container-level monitoring

### Metrics

- **Performance Metrics**: Response times and error rates
- **Memory Usage**: Heap and RSS monitoring
- **Business Metrics**: Upload success rates, insight computation times

### Logging

- **Structured JSON Logging**: Machine-readable logs
- **Request/Response Logging**: Complete request tracking
- **Error Logging**: Stack traces and error details
- **Audit Trail**: All operations logged for compliance

### Monitoring Design Decisions

#### **1. Structured Logging**

- **Decision**: JSON-formatted logs with correlation IDs
- **Rationale**: Machine-readable, easy to parse, supports log aggregation
- **Implementation**: Custom logger with request context

#### **2. Health Check Strategy**

- **Decision**: Comprehensive health checks including dependencies
- **Rationale**: Quick failure detection, automated monitoring
- **Implementation**: Custom health controller with database connectivity checks

#### **3. Metrics Collection**

- **Decision**: Application-level metrics for business KPIs
- **Rationale**: Business insights, performance monitoring
- **Implementation**: Custom interceptors for response time tracking

## üéØ Production Considerations

### Scalability

- **Stateless Design**: Horizontal scaling support
- **Database Connection Pooling**: Efficient connection management
- **Async Processing**: Background processing for heavy operations
- **File Storage Abstraction**: Cloud deployment ready

### Reliability

- **Graceful Shutdown**: Proper signal handling
- **Database Transactions**: ACID compliance
- **Retry Logic**: External service resilience
- **Comprehensive Error Handling**: Graceful failure modes

### Performance

- **Database Indexing**: Optimized query performance
- **Pagination**: Large dataset handling
- **File Streaming**: Efficient large file processing
- **Response Caching**: Where appropriate

### Maintenance

- **Database Migrations**: Schema version control
- **Environment Configuration**: Flexible deployment
- **Docker Health Checks**: Automated monitoring
- **Automated Backups**: Data protection

## üÜò Troubleshooting

### Common Issues

#### 1. Database Connection Issues

```bash
# Check if MySQL is running
docker-compose ps

# View MySQL logs
docker-compose logs mysql

# Connect to MySQL directly
docker-compose exec mysql mysql -u credit_user -p credit_insight_db
```

#### 2. Application Startup Issues

```bash
# Check application logs
docker-compose logs app

# Verify environment variables
docker-compose exec app env | grep DB_

# Check health endpoint
curl http://localhost:3000/health
```

#### 3. File Upload Issues

```bash
# Check file permissions
ls -la uploads/

# Verify CSV format
head -5 your_file.csv

# Check file size limits
du -h your_file.csv
```

#### 4. Authentication Issues

```bash
# Verify JWT token
echo "YOUR_TOKEN" | jwt decode

# Check user in database
docker-compose exec mysql mysql -u root -p -e "SELECT * FROM users;"
```

### Debug Mode

```bash
# Start in debug mode
npm run start:debug

# Or with Docker
docker-compose -f docker-compose.yml up --build
```

### Log Levels

```bash
# Set log level in .env
LOG_LEVEL=debug

# View detailed logs
docker-compose logs -f app | grep -E "(ERROR|WARN|DEBUG)"
```

## ü§ù Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature-name`
3. **Make changes and add tests**
4. **Run tests**: `npm test`
5. **Commit changes**: `git commit -am 'Add feature'`
6. **Push to branch**: `git push origin feature-name`
7. **Create a Pull Request**

### Development Guidelines

- **Code Style**: Follow ESLint and Prettier configuration
- **Testing**: Add tests for new functionality
- **Documentation**: Update README and API docs
- **Security**: Follow security best practices
- **Performance**: Consider performance implications

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

For issues and questions:

1. **Check the [API documentation](http://localhost:3000/api)**
2. **Review the [health endpoints](http://localhost:3000/health)**
3. **Check Docker logs**: `docker-compose logs`
4. **Open an issue on GitHub**

---

**Built with ‚ù§Ô∏è using NestJS, TypeScript, and Docker**

_For more information, visit the [API Documentation](http://localhost:3000/api) or check the [Health Status](http://localhost:3000/health)._
